{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOPqfMqv71Jzwve9I1SezB9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Do-Nhat-Truong/AI-VietNam-Module4-week1/blob/main/week1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RrPAjjYowgp6"
      },
      "outputs": [],
      "source": [
        "# Bài tập 1\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "def get_collume(data,index):\n",
        "    result = [row[index] for row in data]\n",
        "    return result\n",
        "\n",
        "def prepare_data(file_name):\n",
        "    data = np.genfromtxt(file_name,delimiter=',',skip_header=1).tolist()\n",
        "    N=len(data)\n",
        "    tv_data=get_collume(data,0)\n",
        "    radio_data=get_collume(data,1)\n",
        "    newspaper_data=get_collume(data,2)\n",
        "    sales_data=get_collume(data,3)\n",
        "    X=[tv_data,radio_data,newspaper_data]\n",
        "    Y=sales_data\n",
        "    #print(X)\n",
        "    #print(Y)\n",
        "    return X,Y\n",
        "\n",
        "X , y = prepare_data('sample_data/advertising.csv')\n",
        "list = [sum(X[0][:5]),sum(X[1][:5]),sum(X[2][:5]),sum(y[:5])]\n",
        "print(list)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Bài tập 2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "def get_collume(data,index):\n",
        "    result = [row[index] for row in data]\n",
        "    return result\n",
        "\n",
        "def prepare_data(file_name):\n",
        "    data = np.genfromtxt(file_name,delimiter=',',skip_header=1).tolist()\n",
        "    N=len(data)\n",
        "    tv_data=get_collume(data,0)\n",
        "    radio_data=get_collume(data,1)\n",
        "    newspaper_data=get_collume(data,2)\n",
        "    sales_data=get_collume(data,3)\n",
        "    X=[tv_data,radio_data,newspaper_data]\n",
        "    Y=sales_data\n",
        "    #print(X)\n",
        "    #print(Y)\n",
        "    return X,Y\n",
        "# câu 1\n",
        "X,y = prepare_data('sample_data/advertising.csv')\n",
        "#list = [sum(X[0][:5]),sum(X[1][:5]),sum(X[2][:5]),sum(y[:5])]\n",
        "#print(list)\n",
        "\n",
        "def initialize_params () :\n",
        "    # w1 = random . gauss ( mu =0.0 , sigma =0.01)\n",
        "    # w2 = random . gauss ( mu =0.0 , sigma =0.01)\n",
        "    # w3 = random . gauss ( mu =0.0 , sigma =0.01)\n",
        "    # b = 0\n",
        "    w1 , w2 , w3 , b = (0.016992259082509283 , 0.0070783670518262355 ,-0.002307860847821344 , 0)\n",
        "    return w1 , w2 , w3 , b\n",
        "\n",
        "def predict ( x1 , x2 , x3 , w1 , w2 , w3 , b ) :\n",
        "    y_hat = w1 * x1 + w2 * x2 + w3 * x3 + b\n",
        "    return y_hat\n",
        "\n",
        "def compute_loss_mse( y , y_hat ):\n",
        "\n",
        "    # print(f'y: {y}')\n",
        "    # print(f'y_hat: {y_hat}')\n",
        "    # print()\n",
        "    # diff = np.clip(y - y_hat, -1e6, 1e6)\n",
        "    # loss = diff ** 2\n",
        "    loss = (y -y_hat) ** 2\n",
        "    return loss\n",
        "\n",
        "\n",
        "def compute_gradient_wi ( x , y , y_hat ) :\n",
        "    gradient = -2 * x * ( y - y_hat )\n",
        "    return gradient\n",
        "\n",
        "def compute_gradient_b ( y , y_hat ) :\n",
        "    gradient = -2 * ( y - y_hat )\n",
        "    return gradient\n",
        "\n",
        "def update_weight_wi ( w , dl_dw , lr ) :\n",
        "    w = w - lr * dl_dw\n",
        "    return w\n",
        "\n",
        "def update_weight_b ( b , dl_db , lr ) :\n",
        "    b = b - lr * dl_db\n",
        "    return b\n",
        "\n",
        "def implement_linear_regression ( X_data , y_data , epoch_max = 50 , lr = 1e-5) :\n",
        "    losses = []\n",
        "    # b = 0.04\n",
        "    # w = -0.34\n",
        "    # lr = 0.02\n",
        "    w1 , w2 , w3 , b = initialize_params ()\n",
        "\n",
        "    N = len(y_data )\n",
        "    for epoch in range ( epoch_max ) :\n",
        "      for i in range ( N ) :\n",
        "      # get a sample\n",
        "        x1 = X_data[0][i]\n",
        "        x2 = X_data[1][i]\n",
        "        x3 = X_data[2][i]\n",
        "\n",
        "        y = y_data[i]\n",
        "\n",
        "    # compute output\n",
        "        y_hat = predict ( x1 , x2 , x3 , w1 , w2 , w3 , b )\n",
        "\n",
        "    # compute loss\n",
        "        loss = compute_loss_mse (y , y_hat )\n",
        "\n",
        "    # compute gradient w1 , w2 , w3 , b\n",
        "        dl_dw1 = compute_gradient_wi ( x1 , y , y_hat )\n",
        "        dl_dw2 = compute_gradient_wi ( x2 , y , y_hat )\n",
        "        dl_dw3 = compute_gradient_wi ( x3 , y , y_hat )\n",
        "        dl_db = compute_gradient_b (y , y_hat )\n",
        "    # update parameters\n",
        "        w1 = update_weight_wi ( w1 , dl_dw1 , lr )\n",
        "        w2 = update_weight_wi ( w2 , dl_dw2 , lr )\n",
        "        w3 = update_weight_wi ( w3 , dl_dw3 , lr )\n",
        "        b = update_weight_b (b , dl_db , lr )\n",
        "        losses.append(loss)\n",
        "    return ( w1 , w2 , w3 ,b , losses )\n",
        "# Câu 2\n",
        "# y = predict ( x1 =1 , x2 =1 , x3 =1 , w1 =0 , w2 =0.5 , w3 =0 , b =0.5)\n",
        "# print ( y )\n",
        "\n",
        "# Câu 3\n",
        "# l = compute_loss_mse(y_hat =1 , y =0.5)\n",
        "# print ( l )\n",
        "\n",
        "# Câu 4\n",
        "# g_wi = compute_gradient_wi(x= 1.0 , y =1.0 , y_hat =0.5)\n",
        "# print ( g_wi )\n",
        "\n",
        "# Câu 5\n",
        "# g_b = compute_gradient_b ( y =2.0 , y_hat =0.5)\n",
        "# print ( g_b )\n",
        "\n",
        "# Câu 6\n",
        "# after_wi = update_weight_wi( w =1.0 , dl_dw = -0.5 , lr = 1e-5)\n",
        "# print ( after_wi )\n",
        "\n",
        "# Câu 7\n",
        "# after_b = update_weight_b( b =0.5 , dl_db = -1.0 , lr = 1e-5)\n",
        "# print ( after_b )\n",
        "# print ( after_wi )\n",
        "\n",
        "# Câu 8\n",
        "# ( w1 , w2 , w3 ,b , losses ) = implement_linear_regression (X , y )\n",
        "# print ( w1 , w2 , w3 )\n",
        "\n",
        "# Câu 9\n",
        "\n",
        "# tv = 19.2\n",
        "# radio = 35.9\n",
        "# newspaper = 51.3\n",
        "# ( w1 , w2 , w3 ,b , losses ) = implement_linear_regression(X , y , epoch_max =50 , lr =1e-5)\n",
        "# sales = predict( tv , radio , newspaper , w1 , w2 , w3 , b )\n",
        "# print (f'predicted sales is { sales }')\n",
        "\n",
        "# Câu 10\n",
        "l = compute_loss_mse(y_hat =1 , y =0.5)\n",
        "print ( l )\n",
        "\n",
        "#print(X,y)\n",
        "# (w1 , w2 , w3 ,b , losses ) = implement_linear_regression(X,y)\n",
        "\n",
        "\n",
        "# plt . plot( losses[:100])\n",
        "# plt . xlabel(\"# iteration \")\n",
        "# plt . ylabel(\" Loss \")\n",
        "# plt . show()"
      ],
      "metadata": {
        "id": "-JXz9Cscwnly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bài tập 3\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "def get_collume(data,index):\n",
        "    result = [row[index] for row in data]\n",
        "    return result\n",
        "\n",
        "def prepare_data(file_name):\n",
        "    data = np.genfromtxt(file_name,delimiter=',',skip_header=1).tolist()\n",
        "    N=len(data)\n",
        "    tv_data=get_collume(data,0)\n",
        "    radio_data=get_collume(data,1)\n",
        "    newspaper_data=get_collume(data,2)\n",
        "    sales_data=get_collume(data,3)\n",
        "    X=[tv_data,radio_data,newspaper_data]\n",
        "    Y=sales_data\n",
        "    #print(X)\n",
        "    #print(Y)\n",
        "    return X,Y\n",
        "# câu 1\n",
        "X,y = prepare_data('sample_data/advertising.csv')\n",
        "#list = [sum(X[0][:5]),sum(X[1][:5]),sum(X[2][:5]),sum(y[:5])]\n",
        "#print(list)\n",
        "\n",
        "def initialize_params () :\n",
        "    # w1 = random . gauss ( mu =0.0 , sigma =0.01)\n",
        "    # w2 = random . gauss ( mu =0.0 , sigma =0.01)\n",
        "    # w3 = random . gauss ( mu =0.0 , sigma =0.01)\n",
        "    # b = 0\n",
        "    w1 , w2 , w3 , b = (0.016992259082509283 , 0.0070783670518262355 ,-0.002307860847821344 , 0)\n",
        "    return w1 , w2 , w3 , b\n",
        "\n",
        "def predict ( x1 , x2 , x3 , w1 , w2 , w3 , b ) :\n",
        "    y_hat = w1 * x1 + w2 * x2 + w3 * x3 + b\n",
        "    return y_hat\n",
        "\n",
        "def compute_loss_mse( y , y_hat ):\n",
        "\n",
        "    # print(f'y: {y}')\n",
        "    # print(f'y_hat: {y_hat}')\n",
        "    # print()\n",
        "    # diff = np.clip(y - y_hat, -1e6, 1e6)\n",
        "    # loss = diff ** 2\n",
        "    loss = (y-y_hat) ** 2\n",
        "    return loss\n",
        "\n",
        "\n",
        "def compute_gradient_wi ( x , y , y_hat ) :\n",
        "    gradient = -2 * x * ( y - y_hat )\n",
        "    return gradient\n",
        "\n",
        "def compute_gradient_b ( y , y_hat ) :\n",
        "    gradient = -2 * ( y - y_hat )\n",
        "    return gradient\n",
        "\n",
        "def update_weight_wi ( w , dl_dw , lr ) :\n",
        "    w = w - lr * dl_dw\n",
        "    return w\n",
        "\n",
        "def update_weight_b ( b , dl_db , lr ) :\n",
        "    b = b - lr * dl_db\n",
        "    return b\n",
        "\n",
        "def implement_linear_regression_nsamples ( X_data , y_data , epoch_max=50 , lr=1e-5):\n",
        "    losses = []\n",
        "    # b = 0.04\n",
        "    # w = -0.34\n",
        "    # lr = 0.02\n",
        "    w1 , w2 , w3 , b = initialize_params ()\n",
        "\n",
        "    N = len(y_data )\n",
        "    for epoch in range ( epoch_max ) :\n",
        "      loss_total = 0.0\n",
        "      dw1_total = 0.0\n",
        "      dw2_total = 0.0\n",
        "      dw3_total = 0.0\n",
        "      db_total = 0.0\n",
        "      for i in range ( N ) :\n",
        "        # get a sample\n",
        "        x1 = X_data[0][i]\n",
        "        x2 = X_data[1][i]\n",
        "        x3 = X_data[2][i]\n",
        "        y = y_data[i]\n",
        "\n",
        "        # compute output\n",
        "        y_hat = predict ( x1 , x2 , x3 , w1 , w2 , w3 , b )\n",
        "\n",
        "        # compute loss\n",
        "        loss = compute_loss_mse (y , y_hat )\n",
        "        # accumulate loss\n",
        "        loss_total+=loss\n",
        "        # compute gradient w1 , w2 , w3 , b\n",
        "        dl_dw1 = compute_gradient_wi ( x1 , y , y_hat )\n",
        "        dl_dw2 = compute_gradient_wi ( x2 , y , y_hat )\n",
        "        dl_dw3 = compute_gradient_wi ( x3 , y , y_hat )\n",
        "        dl_db = compute_gradient_b (y , y_hat )\n",
        "      # accumulate gradient\n",
        "        dw1_total += dl_dw1\n",
        "        dw2_total += dl_dw2\n",
        "        dw3_total += dl_dw3\n",
        "        db_total += dl_db\n",
        "    # update parameters\n",
        "      w1 = update_weight_wi ( w1 , dw1_total/N , lr )\n",
        "      w2 = update_weight_wi ( w2 , dw2_total/N , lr )\n",
        "      w3 = update_weight_wi ( w3 , dw3_total/N , lr )\n",
        "      b = update_weight_b (b , db_total/N , lr )\n",
        "      losses.append ( loss_total / N )\n",
        "    return ( w1 , w2 , w3 ,b , losses )\n",
        "\n",
        "#print(X,y)\n",
        "# (w1,w2,w3,b,losses) = implement_linear_regression_nsamples(X , y , epoch_max =1000 ,lr =1e-5)\n",
        "# print ( losses )\n",
        "# plt . plot( losses)\n",
        "# plt . xlabel(\"# iteration \")\n",
        "# plt . ylabel(\" Loss \")\n",
        "# plt . show()\n",
        "\n",
        "\n",
        "#Câu 11\n",
        "( w1 , w2 , w3 ,b , losses ) = implement_linear_regression_nsamples (X , y ,1000)\n",
        "print ( w1 , w2 , w3 )"
      ],
      "metadata": {
        "id": "hlf_E3PlwtlH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61f187bf-8ca8-443b-fe36-d0fa62cd02ea"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.06710990754044266 0.15756173831487585 0.029619799386084403\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Bài tập 4\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "def get_collume(data,index):\n",
        "    result = [row[index] for row in data]\n",
        "    return result\n",
        "\n",
        "def prepare_data(file_name):\n",
        "    data = np.genfromtxt(file_name,delimiter=',',skip_header=1).tolist()\n",
        "    N=len(data)\n",
        "    tv_data=get_collume(data,0)\n",
        "    radio_data=get_collume(data,1)\n",
        "    newspaper_data=get_collume(data,2)\n",
        "    sales_data=get_collume(data,3)\n",
        "    X = [[1 , x1 , x2 , x3 ] for x1 , x2 , x3 in zip( tv_data , radio_data , newspaper_data ) ]\n",
        "    # X=[tv_data,radio_data,newspaper_data]\n",
        "    Y=sales_data\n",
        "    #print(X)\n",
        "    #print(Y)\n",
        "    return X,Y\n",
        "def initialize_params () :\n",
        "    # w1 = random . gauss ( mu =0.0 , sigma =0.01)\n",
        "    # w2 = random . gauss ( mu =0.0 , sigma =0.01)\n",
        "    # w3 = random . gauss ( mu =0.0 , sigma =0.01)\n",
        "    # b = 0\n",
        "    # w1 , w2 , w3 , b = (0.016992259082509283 , 0.0070783670518262355 ,-0.002307860847821344 , 0)\n",
        "    # return w1 , w2 , w3 , b\n",
        "    return [0 , -0.01268850433497871 , 0.004752496982185252 , 0.0073796171538643845]\n",
        "def predict(X_features, weights) :\n",
        "    result=0\n",
        "    for i in range(len(weights)):\n",
        "        result+=weights[i]*X_features[i]\n",
        "    return result\n",
        "# def predict ( x1 , x2 , x3 , w1 , w2 , w3 , b ) :\n",
        "#     y_hat = w1 * x1 + w2 * x2 + w3 * x3 + b\n",
        "#     return y_hat\n",
        "\n",
        "def compute_loss( y_hat,y ):\n",
        "    loss = (y_hat-y) ** 2\n",
        "    return loss\n",
        "\n",
        "def compute_gradient_w(x_features,y,y_hat):\n",
        "    result = []\n",
        "    for i in range(len(x_features)):\n",
        "        result.append(2*(y_hat-y)*x_features[i])\n",
        "    return result\n",
        "\n",
        "def update_weight(weights , dl_dweights , lr):\n",
        "    for i in range(len(weights)):\n",
        "        weights[i]=weights[i]-lr*dl_dweights[i]\n",
        "    return weights\n",
        "\n",
        "def implement_linear_regression ( X_feature , y_ouput , epoch_max=50 , lr=1e-5):\n",
        "    losses = []\n",
        "    weights = initialize_params ()\n",
        "    N = len( y_ouput )\n",
        "    for epoch in range ( epoch_max ) :\n",
        "      #print (\" epoch \", epoch )\n",
        "      for i in range ( N ) :\n",
        "        # get a sample - row i\n",
        "        features_i = X_feature [ i ]\n",
        "        y = y_ouput [i]\n",
        "\n",
        "        # compute output\n",
        "        y_hat = predict(features_i , weights )\n",
        "\n",
        "        # compute loss\n",
        "        loss = compute_loss(y , y_hat )\n",
        "\n",
        "        # compute gradient w1 , w2 , w3 , b\n",
        "        dl_dweights = compute_gradient_w ( features_i , y , y_hat )\n",
        "        # print(weights)\n",
        "        # update parameters\n",
        "        weights = update_weight(weights , dl_dweights , lr )\n",
        "\n",
        "        # logging\n",
        "        losses.append( loss )\n",
        "\n",
        "    return (weights , losses)\n",
        "\n",
        "#Câu 12\n",
        "X,y = prepare_data('sample_data/advertising.csv')\n",
        "W , L = implement_linear_regression (X , y , epoch_max =50 , lr =1e-5)\n",
        "# Print loss value at iteration 9999\n",
        "print ( L [9999])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LzVYpE8loW4s",
        "outputId": "4e53a3d6-9fd8-4812-d5f6-4c470572596f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "31.339223408109948\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mục mới"
      ],
      "metadata": {
        "id": "x4AUZDR4-6pp"
      }
    }
  ]
}